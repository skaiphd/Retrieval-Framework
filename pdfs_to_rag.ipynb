{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MathpixConverter with LlamaIndex RAG ðŸ“šðŸ¦™\n",
    "\n",
    "This notebook demonstrates a simple workflow for converting papers from PDF to plain text, and then setting up a query engine on top of converted documents.\n",
    "\n",
    "Since PDF conversion involves replacing tables and diagrams with text, we're going to need to set up an LLM and a VLM to do that. We're going to be using OpenAI's GPT-4 and GPT-4V."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d9c773a2b0d52ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Environment\n",
    "\n",
    "Start by setting necessary environment variables in the `.env` file.\n",
    "\n",
    "- `MATHPIX_APP_ID`\n",
    "- `MATHPIX_APP_KEY`\n",
    "- `OPENAI_API_KEY`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba3fecc8ccb08a4e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv(\".env\"))  # read local .env file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "546bdb1f0b18d4d2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "375c2c8974cb6743",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Converter \n",
    "\n",
    "`MathpixPdfConverter` uses LangChain abstractions to interact with LLMs. It takes a text and a vision model in its constructor.\n",
    "Note that the prompts were tuned to work with GPT-4."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c66545f06913a6b4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "from llama_index.multi_modal_llms import OpenAIMultiModal\n",
    "from pdf_processor.core import MathpixPdfConverter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3698ac0cc711b45a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text_model = OpenAI()\n",
    "vision_model = OpenAIMultiModal(max_new_tokens=4096)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb639e95140289e5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "converter = MathpixPdfConverter(text_model=text_model, vision_model=vision_model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63b0151ec9cf2235",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're going to set up an `inbox` directory to store our unprocessed PDFs, as well as `fulltext` directory to record converter's outputs.\n",
    "Then, we're going to convert PDFs one by one.\n",
    "\n",
    "The converter outputs a `PdfResult` object that contains the final text in the `.content` field, as well as intermediate result of the conversion."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f544263ba4dc5e7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "inbox_path = Path(\"./inbox\")\n",
    "fulltext_path = Path(\"./fulltext\")\n",
    "fulltext_path.mkdir(exist_ok=True, parents=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecc5fb9dd7a83881",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for pdf_path in inbox_path.glob(\"*.pdf\"):\n",
    "    pdf_result = converter.convert(pdf_path)\n",
    "    with fulltext_path.joinpath(f\"{pdf_path.stem}.txt\").open(\"w\") as f:\n",
    "        f.write(pdf_result.content)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa638a4da7692021",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Query Engine\n",
    "\n",
    "Now let's set up a basic LlamaIndex Query Engine to be able to query our converted documents. Inside, the `rag_factory` follows this [Starter Tutorial](https://docs.llamaindex.ai/en/stable/getting_started/starter_example.html)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b17ffcf27f31fd37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rag_factory import build_query_engine"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "query_engine = build_query_engine(fulltext_path.as_posix())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92014311d5222f45",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response = query_engine.query(\"How do action unit activations correspond to stress?\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd1d2024e1d5b49b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "We're going to calculate the RAG triad of metrics using TruLens integration with LlamaIndex."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4344de885bd7ca40"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from trulens_eval import Tru, Feedback, TruLlama\n",
    "from trulens_eval.feedback import Groundedness\n",
    "from trulens_eval.feedback.provider import OpenAI as TruLensOpenAI\n",
    "\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d29cc55c5bba4d5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tru = Tru()\n",
    "tru.reset_database()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98aab5421b86ddca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "provider = TruLensOpenAI(model_engine=\"gpt-4\")\n",
    "context = TruLlama.select_source_nodes().node.text  # select context to provide it to the feedback function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60249d6eac4c34ab",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're going to define a feedback function for each of the metrics."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df439bbacd6ca62b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(provider.relevance_with_cot_reasons).on_input_output()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecd5798005f30a67",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grounded = Groundedness(groundedness_provider=provider)\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons)\n",
    "    .on(context.collect())  # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ee19c0c218f9d3c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "f_context_relevance = (\n",
    "    Feedback(provider.qs_relevance_with_cot_reasons)\n",
    "    .on_input()\n",
    "    .on(context)\n",
    "    .aggregate(np.mean)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "617fe0c9ced7ff24",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Come up with queries to calculate the scores on, and run evaluation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6773d8d65cb0e3fc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tru_recorder = TruLlama(\n",
    "    query_engine,\n",
    "    app_id=\"App_1\",\n",
    "    feedbacks=[\n",
    "        f_qa_relevance,\n",
    "        f_context_relevance,\n",
    "        f_groundedness\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50fc7cb02c74d8de",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"How do action unit activations correspond to stress?\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47303317bc732047",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        query_engine.query(question)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea356832151b6eec",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display the results."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20a549c4ec2378f9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfb71901f0c5a7b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d45e288d39868d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
